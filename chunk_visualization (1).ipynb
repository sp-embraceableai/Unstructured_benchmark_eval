{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ9IIBQvZ7GV",
        "outputId": "36f204e0-5eb9-4fe8-a2c6-d896b8fafe4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: markitdown[all] in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (4.13.4)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (3.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (0.7.1)\n",
            "Requirement already satisfied: magika~=0.6.1 in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (0.6.2)\n",
            "Requirement already satisfied: markdownify in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (2.32.3)\n",
            "Collecting azure-ai-documentintelligence (from markitdown[all])\n",
            "  Downloading azure_ai_documentintelligence-1.0.2-py3-none-any.whl.metadata (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-identity (from markitdown[all])\n",
            "  Downloading azure_identity-1.23.1-py3-none-any.whl.metadata (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.4/82.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (5.4.0)\n",
            "Collecting mammoth (from markitdown[all])\n",
            "  Downloading mammoth-1.9.1-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting olefile (from markitdown[all])\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (3.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (2.2.2)\n",
            "Collecting pdfminer-six (from markitdown[all])\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (0.25.1)\n",
            "Collecting python-pptx (from markitdown[all])\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting speechrecognition (from markitdown[all])\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (2.0.2)\n",
            "Collecting youtube-transcript-api~=1.0.0 (from markitdown[all])\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from magika~=0.6.1->markitdown[all]) (8.2.1)\n",
            "Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from magika~=0.6.1->markitdown[all]) (1.22.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from magika~=0.6.1->markitdown[all]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from magika~=0.6.1->markitdown[all]) (1.1.1)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-documentintelligence->markitdown[all])\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core>=1.30.0 (from azure-ai-documentintelligence->markitdown[all])\n",
            "  Downloading azure_core-1.35.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from azure-ai-documentintelligence->markitdown[all]) (4.14.1)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.11/dist-packages (from azure-identity->markitdown[all]) (43.0.3)\n",
            "Collecting msal>=1.30.0 (from azure-identity->markitdown[all])\n",
            "  Downloading msal-1.33.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->markitdown[all])\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->markitdown[all]) (2.7)\n",
            "Collecting cobble<0.2,>=0.1.3 (from mammoth->markitdown[all])\n",
            "  Downloading cobble-0.1.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.11/dist-packages (from markdownify->markitdown[all]) (1.17.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->markitdown[all]) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown[all]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown[all]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown[all]) (2025.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx->markitdown[all]) (11.3.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->markitdown[all])\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->markitdown[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->markitdown[all]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->markitdown[all]) (2025.7.14)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.5->azure-identity->markitdown[all]) (1.17.1)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->markitdown[all]) (2.10.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (1.13.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->markitdown[all]) (2.22)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (1.3.0)\n",
            "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_documentintelligence-1.0.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.23.1-py3-none-any.whl (186 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mammoth-1.9.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.35.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cobble-0.1.4-py3-none-any.whl (4.0 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading msal-1.33.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, speechrecognition, olefile, isodate, cobble, youtube-transcript-api, python-pptx, mammoth, azure-core, pdfminer-six, azure-ai-documentintelligence, msal, msal-extensions, azure-identity\n",
            "Successfully installed XlsxWriter-3.2.5 azure-ai-documentintelligence-1.0.2 azure-core-1.35.0 azure-identity-1.23.1 cobble-0.1.4 isodate-0.7.2 mammoth-1.9.1 msal-1.33.0 msal-extensions-1.3.1 olefile-0.47 pdfminer-six-20250506 python-pptx-1.0.2 speechrecognition-3.14.3 youtube-transcript-api-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install markitdown[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# short chunk test.\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "# Cell 2: Setup Input/Output Paths\n",
        "pdf_path = \"/content/BAnz AT 02.04.2024 B3.pdf\"\n",
        "output_md_path = \"/content/example.md\"\n",
        "\n",
        "# Cell 3: Convert PDF to Markdown with MarkItDown\n",
        "converter = MarkItDown()\n",
        "result = converter.convert(pdf_path)\n",
        "markdown = result.markdown  # Extract markdown string\n",
        "\n",
        "# Save to markdown file (optional)\n",
        "with open(output_md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(markdown)\n",
        "\n",
        "print(\"✅ Markdown conversion complete.\")\n",
        "\n",
        "# Cell 4: Paragraph-aware splitter\n",
        "def split_paragraphwise(text, max_chars=2000):\n",
        "    \"\"\"\n",
        "    Split a page into chunks at paragraph boundaries (not mid-sentence).\n",
        "    \"\"\"\n",
        "    paragraphs = text.split(\"\\n\\n\")\n",
        "    chunks, current = [], \"\"\n",
        "\n",
        "    for para in paragraphs:\n",
        "        if len(current) + len(para) + 2 <= max_chars:\n",
        "            current += \"\\n\\n\" + para\n",
        "        else:\n",
        "            if current.strip():\n",
        "                chunks.append(current.strip())\n",
        "            current = para\n",
        "    if current.strip():\n",
        "        chunks.append(current.strip())\n",
        "    return chunks\n",
        "\n",
        "# Cell 5: Chunking Markdown by Page, with paragraph-aware splits\n",
        "def chunk_markdown_by_page(md_text, max_chars=2000):\n",
        "    chunks = []\n",
        "    pages = re.split(r\"(<!-- Page: \\d+ -->)\", md_text)\n",
        "\n",
        "    grouped_pages = []\n",
        "    for i in range(0, len(pages), 2):\n",
        "        page_marker = pages[i].strip()\n",
        "        content = pages[i + 1].strip() if i + 1 < len(pages) else \"\"\n",
        "        full_page = f\"{page_marker}\\n{content}\".strip()\n",
        "        grouped_pages.append(full_page)\n",
        "\n",
        "    for page in grouped_pages:\n",
        "        if len(page) <= max_chars:\n",
        "            chunks.append(page.strip())\n",
        "        else:\n",
        "            subchunks = split_paragraphwise(page, max_chars=max_chars)\n",
        "            chunks.extend(subchunks)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Cell 6: Run Chunking\n",
        "chunks = chunk_markdown_by_page(markdown, max_chars=2000)\n",
        "\n",
        "# Print summary\n",
        "print(f\"✅ Total chunks created: {len(chunks)}\")\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "    print(f\"\\n--- Chunk {i + 1} ---\\n{chunk[:500]}...\")\n",
        "\n",
        "# Cell 7: Save chunks to disk\n",
        "output_dir = Path(\"/content/markdown_chunks\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    with open(output_dir / f\"chunk_{i+1:03d}.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(chunk)\n",
        "\n",
        "print(f\"✅ All chunks saved to: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNmZoPrHf-4z",
        "outputId": "73c3b2aa-5135-4030-9c4b-46827fadfb12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Markdown conversion complete.\n",
            "✅ Total chunks created: 20\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Bekanntmachung\n",
            "Veröffentlicht am Dienstag, 2. April 2024\n",
            "BAnz AT 02.04.2024 B3\n",
            "Seite 1 von 7\n",
            "\n",
            "Bundesministerium\n",
            "für Umwelt, Naturschutz, nukleare Sicherheit und Verbraucherschutz\n",
            "\n",
            "Förderrichtlinie\n",
            "für Maßnahmen der Künstlichen Intelligenz\n",
            "„KI-Leuchttürme für den Natürlichen Klimaschutz“\n",
            "\n",
            "Vom 19. März 2024\n",
            "\n",
            "1   Förderziel, Zuwendungszweck, Rechtsgrundlage\n",
            "\n",
            "1.1  Förderziel und Zuwendungszweck\n",
            "\n",
            "Der Natürliche Klimaschutz spielt eine zentrale Rolle bei der Bewältigung der Klimakrise und ihrer Folgen...\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Das Bundesministerium für Umwelt, Naturschutz, nukleare Sicherheit und Verbraucherschutz (BMUV) setzt sich mit\n",
            "dem  5-Punkte-Programm  „Künstliche  Intelligenz  für  Umwelt  und  Klima“  für  eine  umweltpolitische  Gestaltung  von\n",
            "Künstlicher  Intelligenz  ein.  Ein  maßgebliches  Instrument  zur  Erreichung  dieser  Ziele  ist  eine  gezielte  Innovations-\n",
            "förderung  für  eine  Technologieentwicklung,  die  am  Gemeinwohl  orientiert  ist  und  zur  Erreichung  der  Agenda  2030\n",
            "der Vereinten ...\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Übergeordnetes Förderziel dieser Richtlinie ist es, einen Beitrag zum Natürlichen Klimaschutz und damit zur Abmil-\n",
            "derung  des  Klimawandels  und  seiner  Folgen  sowie  zur  Vorsorge  und  Anpassung  an  Klimawandelfolgen  zu  leisten.\n",
            "Gleichzeitig sollen die sozial-ökologische Transformation vorangetrieben und der gesellschaftliche Diskurs zu KI für\n",
            "den Natürlichen Klimaschutz gestärkt werden.\n",
            "\n",
            "Die Förderung umfasst Projekte, die mittels KI im Sinne Maschinellen Lernens dem Erhalt beziehungswe...\n",
            "✅ All chunks saved to: /content/markdown_chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5B: Evaluate chunk quality heuristically\n",
        "\n",
        "# 1. Average length\n",
        "avg_len = sum(len(c) for c in chunks) / len(chunks)\n",
        "print(f\"\\n📏 Average chunk length: {avg_len:.0f} characters\")\n",
        "\n",
        "# 2. Short chunk warning (<300 chars)\n",
        "short_chunks = [i for i, c in enumerate(chunks) if len(c) < 300]\n",
        "print(f\"⚠️ Chunks under 300 characters: {len(short_chunks)} → Indexes: {short_chunks[:10]}\")\n",
        "\n",
        "# 3. Table integrity check (split tables)\n",
        "possible_split_tables = [i for i, c in enumerate(chunks) if '|' in c and c.count('|') < 3]\n",
        "print(f\"🧩 Possibly split table chunks: {len(possible_split_tables)} → {possible_split_tables[:10]}\")\n",
        "\n",
        "# 4. Page boundary check\n",
        "pages_detected = sum('<!-- Page:' in c for c in chunks)\n",
        "print(f\"📄 Page markers detected in chunks: {pages_detected}/{len(chunks)}\")\n",
        "\n",
        "# 5. Print one short chunk for inspection\n",
        "if short_chunks:\n",
        "    print(\"\\n🕵️ Example short chunk:\")\n",
        "    print(f\"\\n--- Chunk {short_chunks[0]+1} ---\\n{chunks[short_chunks[0]]}\")"
      ],
      "metadata": {
        "id": "yqr2gqTDhTvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Table chunk test\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "# Cell 2: Setup Input/Output Paths\n",
        "pdf_path = \"/content/bw_budget_02_01_Epl.pdf\"\n",
        "output_md_path = \"/content/example.md\"\n",
        "\n",
        "# Cell 3: Convert PDF to Markdown with MarkItDown\n",
        "converter = MarkItDown()\n",
        "result = converter.convert(pdf_path)\n",
        "markdown = result.markdown  # Extract markdown string\n",
        "\n",
        "# Save to markdown file (optional)\n",
        "with open(output_md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(markdown)\n",
        "\n",
        "print(\"✅ Markdown conversion complete.\")\n",
        "\n",
        "# Cell 4: Table-safe paragraph-aware splitter\n",
        "def split_paragraphwise_table_safe(text, max_chars=2000):\n",
        "    \"\"\"\n",
        "    Split text into chunks at paragraph boundaries,\n",
        "    but keep markdown tables intact (do not split inside tables).\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    def flush():\n",
        "        if current_chunk:\n",
        "            chunks.append(\"\\n\".join(current_chunk).strip())\n",
        "            current_chunk.clear()\n",
        "\n",
        "    in_table = False\n",
        "    current_len = 0\n",
        "\n",
        "    for line in lines:\n",
        "        # Detect markdown table lines (heuristic)\n",
        "        is_table_line = \"|\" in line and not line.strip().startswith(\"#\")\n",
        "\n",
        "        if is_table_line:\n",
        "            in_table = True\n",
        "        elif in_table and line.strip() == \"\":\n",
        "            # Blank line ends a table block\n",
        "            in_table = False\n",
        "\n",
        "        line_len = len(line) + 1  # including newline\n",
        "        # If adding this line exceeds max_chars and we are not inside a table, flush current chunk\n",
        "        if current_len + line_len > max_chars and not in_table:\n",
        "            flush()\n",
        "            current_chunk.append(line)\n",
        "            current_len = line_len\n",
        "        else:\n",
        "            current_chunk.append(line)\n",
        "            current_len += line_len\n",
        "\n",
        "    flush()\n",
        "    return chunks\n",
        "\n",
        "# Cell 5: Chunking Markdown by Page with table-safe paragraph splits\n",
        "def chunk_markdown_by_page(md_text, max_chars=2000):\n",
        "    chunks = []\n",
        "    # Split by page markers (keep markers)\n",
        "    pages = re.split(r\"(<!-- Page: \\d+ -->)\", md_text)\n",
        "\n",
        "    grouped_pages = []\n",
        "    for i in range(0, len(pages), 2):\n",
        "        page_marker = pages[i].strip()\n",
        "        content = pages[i + 1].strip() if i + 1 < len(pages) else \"\"\n",
        "        full_page = f\"{page_marker}\\n{content}\".strip()\n",
        "        grouped_pages.append(full_page)\n",
        "\n",
        "    for page in grouped_pages:\n",
        "        if len(page) <= max_chars:\n",
        "            chunks.append(page.strip())\n",
        "        else:\n",
        "            # Use table-safe splitter to avoid breaking tables\n",
        "            subchunks = split_paragraphwise_table_safe(page, max_chars=max_chars)\n",
        "            chunks.extend(subchunks)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Cell 6: Run Chunking\n",
        "chunks = chunk_markdown_by_page(markdown, max_chars=2000)\n",
        "\n",
        "# Print summary for first few chunks\n",
        "print(f\"✅ Total chunks created: {len(chunks)}\")\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "    print(f\"\\n--- Chunk {i + 1} ---\\n{chunk[:500]}...\")\n",
        "\n",
        "# Cell 7: Save chunks to disk\n",
        "output_dir = Path(\"/content/markdown_chunks\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    with open(output_dir / f\"chunk_{i+1:03d}.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(chunk)\n",
        "\n",
        "print(f\"✅ All chunks saved to: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztLitsy_hkTv",
        "outputId": "135dcec7-4939-4138-acd6-d934d16283c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Markdown conversion complete.\n",
            "✅ Total chunks created: 66\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Staatshaushaltsplan\n",
            "\n",
            "für 2025/2026\n",
            "\n",
            "Einzelplan 01\n",
            "\n",
            "Landtag\n",
            "\n",
            "Für den Druck wurde klimaneutral produziertes, weißes Papier verwendet\n",
            "\n",
            "\n",
            "Inhalt\n",
            "\n",
            "Betragsteil\n",
            "Seite\n",
            "\n",
            "Stellenteil\n",
            "Seite\n",
            "\n",
            "Vorwort .................................................................................................................................................................................................\n",
            "\n",
            "Ziele und Kennzahlen (Produktorientierte Informationen) .................................................................\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Die Aufgaben des Landtags sind in der Landesverfassung festgelegt. Artikel 27 Abs. 2 der Verfassung lautet: „Der Landtag übt die gesetzgebende Gewalt aus und über-\n",
            "wacht die Ausübung der vollziehenden Gewalt nach Maßgabe dieser Verfassung.“\n",
            "\n",
            "Das Kapitel 0101 enthält die Ausgaben für die Mitglieder des Landtags sowie die zu erwartenden Einnahmen und Ausgaben, die bei der Erfüllung der dem Landtag\n",
            "obliegenden Aufgaben voraussichtlich zu leisten sind.\n",
            "\n",
            "Dem Landtag gehören in der 17. Wahlperiode 154...\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Ferner ist beim Landtag für die Fraktionen ein parlamentarischer Beratungsdienst eingerichtet.\n",
            "\n",
            "Die Verwaltung des Landtags nimmt die Aufgaben einer obersten Landesbehörde wahr. Sie untersteht der Präsidentin und wird von der Direktorin beim Landtag gelei-\n",
            "tet.\n",
            "\n",
            "Beim Landtag ist außerdem die Dienststelle der Landeszentrale für politische Bildung eingerichtet. Zudem hat die Bürgerbeauftragte des Landes Baden-Württemberg\n",
            "ihren Dienstsitz beim Landtag.\n",
            "\n",
            "Die Landeszentrale für politische Bildung Bad...\n",
            "✅ All chunks saved to: /content/markdown_chunks\n"
          ]
        }
      ]
    }
  ]
}