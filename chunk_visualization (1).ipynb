{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ9IIBQvZ7GV",
        "outputId": "36f204e0-5eb9-4fe8-a2c6-d896b8fafe4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: markitdown[all] in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (4.13.4)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (3.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (0.7.1)\n",
            "Requirement already satisfied: magika~=0.6.1 in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (0.6.2)\n",
            "Requirement already satisfied: markdownify in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (2.32.3)\n",
            "Collecting azure-ai-documentintelligence (from markitdown[all])\n",
            "  Downloading azure_ai_documentintelligence-1.0.2-py3-none-any.whl.metadata (53 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/53.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-identity (from markitdown[all])\n",
            "  Downloading azure_identity-1.23.1-py3-none-any.whl.metadata (82 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.4/82.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (5.4.0)\n",
            "Collecting mammoth (from markitdown[all])\n",
            "  Downloading mammoth-1.9.1-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting olefile (from markitdown[all])\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (3.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (2.2.2)\n",
            "Collecting pdfminer-six (from markitdown[all])\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (0.25.1)\n",
            "Collecting python-pptx (from markitdown[all])\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting speechrecognition (from markitdown[all])\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (from markitdown[all]) (2.0.2)\n",
            "Collecting youtube-transcript-api~=1.0.0 (from markitdown[all])\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from magika~=0.6.1->markitdown[all]) (8.2.1)\n",
            "Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from magika~=0.6.1->markitdown[all]) (1.22.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from magika~=0.6.1->markitdown[all]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from magika~=0.6.1->markitdown[all]) (1.1.1)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-documentintelligence->markitdown[all])\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core>=1.30.0 (from azure-ai-documentintelligence->markitdown[all])\n",
            "  Downloading azure_core-1.35.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from azure-ai-documentintelligence->markitdown[all]) (4.14.1)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.11/dist-packages (from azure-identity->markitdown[all]) (43.0.3)\n",
            "Collecting msal>=1.30.0 (from azure-identity->markitdown[all])\n",
            "  Downloading msal-1.33.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->markitdown[all])\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->markitdown[all]) (2.7)\n",
            "Collecting cobble<0.2,>=0.1.3 (from mammoth->markitdown[all])\n",
            "  Downloading cobble-0.1.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.11/dist-packages (from markdownify->markitdown[all]) (1.17.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->markitdown[all]) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown[all]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown[all]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown[all]) (2025.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx->markitdown[all]) (11.3.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->markitdown[all])\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->markitdown[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->markitdown[all]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->markitdown[all]) (2025.7.14)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.5->azure-identity->markitdown[all]) (1.17.1)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->markitdown[all]) (2.10.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (1.13.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->markitdown[all]) (2.22)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[all]) (1.3.0)\n",
            "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_documentintelligence-1.0.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.0/106.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.23.1-py3-none-any.whl (186 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m186.8/186.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mammoth-1.9.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.35.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cobble-0.1.4-py3-none-any.whl (4.0 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading msal-1.33.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, speechrecognition, olefile, isodate, cobble, youtube-transcript-api, python-pptx, mammoth, azure-core, pdfminer-six, azure-ai-documentintelligence, msal, msal-extensions, azure-identity\n",
            "Successfully installed XlsxWriter-3.2.5 azure-ai-documentintelligence-1.0.2 azure-core-1.35.0 azure-identity-1.23.1 cobble-0.1.4 isodate-0.7.2 mammoth-1.9.1 msal-1.33.0 msal-extensions-1.3.1 olefile-0.47 pdfminer-six-20250506 python-pptx-1.0.2 speechrecognition-3.14.3 youtube-transcript-api-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install markitdown[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# short chunk test.\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "# Cell 2: Setup Input/Output Paths\n",
        "pdf_path = \"/content/BAnz AT 02.04.2024 B3.pdf\"\n",
        "output_md_path = \"/content/example.md\"\n",
        "\n",
        "# Cell 3: Convert PDF to Markdown with MarkItDown\n",
        "converter = MarkItDown()\n",
        "result = converter.convert(pdf_path)\n",
        "markdown = result.markdown  # Extract markdown string\n",
        "\n",
        "# Save to markdown file (optional)\n",
        "with open(output_md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(markdown)\n",
        "\n",
        "print(\"âœ… Markdown conversion complete.\")\n",
        "\n",
        "# Cell 4: Paragraph-aware splitter\n",
        "def split_paragraphwise(text, max_chars=2000):\n",
        "    \"\"\"\n",
        "    Split a page into chunks at paragraph boundaries (not mid-sentence).\n",
        "    \"\"\"\n",
        "    paragraphs = text.split(\"\\n\\n\")\n",
        "    chunks, current = [], \"\"\n",
        "\n",
        "    for para in paragraphs:\n",
        "        if len(current) + len(para) + 2 <= max_chars:\n",
        "            current += \"\\n\\n\" + para\n",
        "        else:\n",
        "            if current.strip():\n",
        "                chunks.append(current.strip())\n",
        "            current = para\n",
        "    if current.strip():\n",
        "        chunks.append(current.strip())\n",
        "    return chunks\n",
        "\n",
        "# Cell 5: Chunking Markdown by Page, with paragraph-aware splits\n",
        "def chunk_markdown_by_page(md_text, max_chars=2000):\n",
        "    chunks = []\n",
        "    pages = re.split(r\"(<!-- Page: \\d+ -->)\", md_text)\n",
        "\n",
        "    grouped_pages = []\n",
        "    for i in range(0, len(pages), 2):\n",
        "        page_marker = pages[i].strip()\n",
        "        content = pages[i + 1].strip() if i + 1 < len(pages) else \"\"\n",
        "        full_page = f\"{page_marker}\\n{content}\".strip()\n",
        "        grouped_pages.append(full_page)\n",
        "\n",
        "    for page in grouped_pages:\n",
        "        if len(page) <= max_chars:\n",
        "            chunks.append(page.strip())\n",
        "        else:\n",
        "            subchunks = split_paragraphwise(page, max_chars=max_chars)\n",
        "            chunks.extend(subchunks)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Cell 6: Run Chunking\n",
        "chunks = chunk_markdown_by_page(markdown, max_chars=2000)\n",
        "\n",
        "# Print summary\n",
        "print(f\"âœ… Total chunks created: {len(chunks)}\")\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "    print(f\"\\n--- Chunk {i + 1} ---\\n{chunk[:500]}...\")\n",
        "\n",
        "# Cell 7: Save chunks to disk\n",
        "output_dir = Path(\"/content/markdown_chunks\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    with open(output_dir / f\"chunk_{i+1:03d}.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(chunk)\n",
        "\n",
        "print(f\"âœ… All chunks saved to: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNmZoPrHf-4z",
        "outputId": "73c3b2aa-5135-4030-9c4b-46827fadfb12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Markdown conversion complete.\n",
            "âœ… Total chunks created: 20\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Bekanntmachung\n",
            "VerÃ¶ffentlicht am Dienstag, 2. April 2024\n",
            "BAnz AT 02.04.2024 B3\n",
            "Seite 1 von 7\n",
            "\n",
            "Bundesministerium\n",
            "fÃ¼r Umwelt, Naturschutz, nukleare Sicherheit und Verbraucherschutz\n",
            "\n",
            "FÃ¶rderrichtlinie\n",
            "fÃ¼r MaÃŸnahmen der KÃ¼nstlichen Intelligenz\n",
            "â€KI-LeuchttÃ¼rme fÃ¼r den NatÃ¼rlichen Klimaschutzâ€œ\n",
            "\n",
            "Vom 19. MÃ¤rz 2024\n",
            "\n",
            "1   FÃ¶rderziel, Zuwendungszweck, Rechtsgrundlage\n",
            "\n",
            "1.1  FÃ¶rderziel und Zuwendungszweck\n",
            "\n",
            "Der NatÃ¼rliche Klimaschutz spielt eine zentrale Rolle bei der BewÃ¤ltigung der Klimakrise und ihrer Folgen...\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Das Bundesministerium fÃ¼r Umwelt, Naturschutz, nukleare Sicherheit und Verbraucherschutz (BMUV) setzt sich mit\n",
            "dem  5-Punkte-Programm  â€KÃ¼nstliche  Intelligenz  fÃ¼r  Umwelt  und  Klimaâ€œ  fÃ¼r  eine  umweltpolitische  Gestaltung  von\n",
            "KÃ¼nstlicher  Intelligenz  ein.  Ein  maÃŸgebliches  Instrument  zur  Erreichung  dieser  Ziele  ist  eine  gezielte  Innovations-\n",
            "fÃ¶rderung  fÃ¼r  eine  Technologieentwicklung,  die  am  Gemeinwohl  orientiert  ist  und  zur  Erreichung  der  Agenda  2030\n",
            "der Vereinten ...\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Ãœbergeordnetes FÃ¶rderziel dieser Richtlinie ist es, einen Beitrag zum NatÃ¼rlichen Klimaschutz und damit zur Abmil-\n",
            "derung  des  Klimawandels  und  seiner  Folgen  sowie  zur  Vorsorge  und  Anpassung  an  Klimawandelfolgen  zu  leisten.\n",
            "Gleichzeitig sollen die sozial-Ã¶kologische Transformation vorangetrieben und der gesellschaftliche Diskurs zu KI fÃ¼r\n",
            "den NatÃ¼rlichen Klimaschutz gestÃ¤rkt werden.\n",
            "\n",
            "Die FÃ¶rderung umfasst Projekte, die mittels KI im Sinne Maschinellen Lernens dem Erhalt beziehungswe...\n",
            "âœ… All chunks saved to: /content/markdown_chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5B: Evaluate chunk quality heuristically\n",
        "\n",
        "# 1. Average length\n",
        "avg_len = sum(len(c) for c in chunks) / len(chunks)\n",
        "print(f\"\\nğŸ“ Average chunk length: {avg_len:.0f} characters\")\n",
        "\n",
        "# 2. Short chunk warning (<300 chars)\n",
        "short_chunks = [i for i, c in enumerate(chunks) if len(c) < 300]\n",
        "print(f\"âš ï¸ Chunks under 300 characters: {len(short_chunks)} â†’ Indexes: {short_chunks[:10]}\")\n",
        "\n",
        "# 3. Table integrity check (split tables)\n",
        "possible_split_tables = [i for i, c in enumerate(chunks) if '|' in c and c.count('|') < 3]\n",
        "print(f\"ğŸ§© Possibly split table chunks: {len(possible_split_tables)} â†’ {possible_split_tables[:10]}\")\n",
        "\n",
        "# 4. Page boundary check\n",
        "pages_detected = sum('<!-- Page:' in c for c in chunks)\n",
        "print(f\"ğŸ“„ Page markers detected in chunks: {pages_detected}/{len(chunks)}\")\n",
        "\n",
        "# 5. Print one short chunk for inspection\n",
        "if short_chunks:\n",
        "    print(\"\\nğŸ•µï¸ Example short chunk:\")\n",
        "    print(f\"\\n--- Chunk {short_chunks[0]+1} ---\\n{chunks[short_chunks[0]]}\")"
      ],
      "metadata": {
        "id": "yqr2gqTDhTvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Table chunk test\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "# Cell 2: Setup Input/Output Paths\n",
        "pdf_path = \"/content/bw_budget_02_01_Epl.pdf\"\n",
        "output_md_path = \"/content/example.md\"\n",
        "\n",
        "# Cell 3: Convert PDF to Markdown with MarkItDown\n",
        "converter = MarkItDown()\n",
        "result = converter.convert(pdf_path)\n",
        "markdown = result.markdown  # Extract markdown string\n",
        "\n",
        "# Save to markdown file (optional)\n",
        "with open(output_md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(markdown)\n",
        "\n",
        "print(\"âœ… Markdown conversion complete.\")\n",
        "\n",
        "# Cell 4: Table-safe paragraph-aware splitter\n",
        "def split_paragraphwise_table_safe(text, max_chars=2000):\n",
        "    \"\"\"\n",
        "    Split text into chunks at paragraph boundaries,\n",
        "    but keep markdown tables intact (do not split inside tables).\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    def flush():\n",
        "        if current_chunk:\n",
        "            chunks.append(\"\\n\".join(current_chunk).strip())\n",
        "            current_chunk.clear()\n",
        "\n",
        "    in_table = False\n",
        "    current_len = 0\n",
        "\n",
        "    for line in lines:\n",
        "        # Detect markdown table lines (heuristic)\n",
        "        is_table_line = \"|\" in line and not line.strip().startswith(\"#\")\n",
        "\n",
        "        if is_table_line:\n",
        "            in_table = True\n",
        "        elif in_table and line.strip() == \"\":\n",
        "            # Blank line ends a table block\n",
        "            in_table = False\n",
        "\n",
        "        line_len = len(line) + 1  # including newline\n",
        "        # If adding this line exceeds max_chars and we are not inside a table, flush current chunk\n",
        "        if current_len + line_len > max_chars and not in_table:\n",
        "            flush()\n",
        "            current_chunk.append(line)\n",
        "            current_len = line_len\n",
        "        else:\n",
        "            current_chunk.append(line)\n",
        "            current_len += line_len\n",
        "\n",
        "    flush()\n",
        "    return chunks\n",
        "\n",
        "# Cell 5: Chunking Markdown by Page with table-safe paragraph splits\n",
        "def chunk_markdown_by_page(md_text, max_chars=2000):\n",
        "    chunks = []\n",
        "    # Split by page markers (keep markers)\n",
        "    pages = re.split(r\"(<!-- Page: \\d+ -->)\", md_text)\n",
        "\n",
        "    grouped_pages = []\n",
        "    for i in range(0, len(pages), 2):\n",
        "        page_marker = pages[i].strip()\n",
        "        content = pages[i + 1].strip() if i + 1 < len(pages) else \"\"\n",
        "        full_page = f\"{page_marker}\\n{content}\".strip()\n",
        "        grouped_pages.append(full_page)\n",
        "\n",
        "    for page in grouped_pages:\n",
        "        if len(page) <= max_chars:\n",
        "            chunks.append(page.strip())\n",
        "        else:\n",
        "            # Use table-safe splitter to avoid breaking tables\n",
        "            subchunks = split_paragraphwise_table_safe(page, max_chars=max_chars)\n",
        "            chunks.extend(subchunks)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Cell 6: Run Chunking\n",
        "chunks = chunk_markdown_by_page(markdown, max_chars=2000)\n",
        "\n",
        "# Print summary for first few chunks\n",
        "print(f\"âœ… Total chunks created: {len(chunks)}\")\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "    print(f\"\\n--- Chunk {i + 1} ---\\n{chunk[:500]}...\")\n",
        "\n",
        "# Cell 7: Save chunks to disk\n",
        "output_dir = Path(\"/content/markdown_chunks\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    with open(output_dir / f\"chunk_{i+1:03d}.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(chunk)\n",
        "\n",
        "print(f\"âœ… All chunks saved to: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztLitsy_hkTv",
        "outputId": "135dcec7-4939-4138-acd6-d934d16283c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Markdown conversion complete.\n",
            "âœ… Total chunks created: 66\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Staatshaushaltsplan\n",
            "\n",
            "fÃ¼r 2025/2026\n",
            "\n",
            "Einzelplan 01\n",
            "\n",
            "Landtag\n",
            "\n",
            "FÃ¼r den Druck wurde klimaneutral produziertes, weiÃŸes Papier verwendet\n",
            "\n",
            "\n",
            "Inhalt\n",
            "\n",
            "Betragsteil\n",
            "Seite\n",
            "\n",
            "Stellenteil\n",
            "Seite\n",
            "\n",
            "VorwortÂ .................................................................................................................................................................................................\n",
            "\n",
            "Ziele und Kennzahlen (Produktorientierte Informationen)Â .................................................................\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Die Aufgaben des Landtags sind in der Landesverfassung festgelegt. Artikel 27 Abs. 2 der Verfassung lautet: â€Der Landtag Ã¼bt die gesetzgebende Gewalt aus und Ã¼ber-\n",
            "wacht die AusÃ¼bung der vollziehenden Gewalt nach MaÃŸgabe dieser Verfassung.â€œ\n",
            "\n",
            "Das Kapitel 0101 enthÃ¤lt die Ausgaben fÃ¼r die Mitglieder des Landtags sowie die zu erwartenden Einnahmen und Ausgaben, die bei der ErfÃ¼llung der dem Landtag\n",
            "obliegenden Aufgaben voraussichtlich zu leisten sind.\n",
            "\n",
            "Dem Landtag gehÃ¶ren in der 17. Wahlperiode 154...\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Ferner ist beim Landtag fÃ¼r die Fraktionen ein parlamentarischer Beratungsdienst eingerichtet.\n",
            "\n",
            "Die Verwaltung des Landtags nimmt die Aufgaben einer obersten LandesbehÃ¶rde wahr. Sie untersteht der PrÃ¤sidentin und wird von der Direktorin beim Landtag gelei-\n",
            "tet.\n",
            "\n",
            "Beim Landtag ist auÃŸerdem die Dienststelle der Landeszentrale fÃ¼r politische Bildung eingerichtet. Zudem hat die BÃ¼rgerbeauftragte des Landes Baden-WÃ¼rttemberg\n",
            "ihren Dienstsitz beim Landtag.\n",
            "\n",
            "Die Landeszentrale fÃ¼r politische Bildung Bad...\n",
            "âœ… All chunks saved to: /content/markdown_chunks\n"
          ]
        }
      ]
    }
  ]
}